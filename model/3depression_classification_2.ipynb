{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25a812e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (78, 402)\n",
      "Missing values in features: 0\n",
      "Missing values in target: 0\n",
      "Class distribution:\n",
      " phq8_binary\n",
      "1    40\n",
      "0    38\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../EDA/final_features_with_labels.csv\")\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "\n",
    "# Drop 'phq8_score' (we're doing classification now)\n",
    "df = df.drop(columns=['phq8_score'])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['participant_id', 'phq8_binary'])\n",
    "y = df['phq8_binary']\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in features:\", X.isnull().sum().sum())\n",
    "print(\"Missing values in target:\", y.isnull().sum())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875983ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_scaled shape: (78, 399)\n",
      "Sample scaled values:\n",
      " [[-1.31677239 -0.37766258 -0.37795489 -0.5042921   0.10229364 -0.82450259\n",
      "   1.21594485  0.02377023  1.02702809 -0.41094428 -0.31739128  0.76740897\n",
      "   0.33733659  0.07421528 -0.50991719  1.46748232  1.70975581 -0.24603016\n",
      "  -0.68111349  0.76527241  0.74878898 -0.1208162  -0.60782038 -0.11960901\n",
      "   1.19304108  0.20491568  0.92966859 -0.33084613 -0.24135471 -1.01918388\n",
      "  -0.42575143 -0.30460835 -0.70419468  0.19302153 -1.00629916  0.59419513\n",
      "  -1.47152497 -1.06918662 -0.18674083  0.93598005 -0.35506097 -0.10842956\n",
      "  -0.25221284  0.73711465  0.4804145   1.85965257  1.12238672 -1.11754195\n",
      "   1.50223259  0.29861037  0.11231986 -0.83226254 -0.61854826  2.77851451\n",
      "   0.03577349  2.37267473 -0.83036748 -1.24876238  0.14399131  0.43560985\n",
      "  -1.20345848  2.23488209  0.33758199  1.38891907 -1.2790472   1.24073423\n",
      "   0.00745768 -0.34289132 -1.81237347 -0.10919865  0.39914677 -0.06902611\n",
      "  -0.30727947  0.55222289  0.3611993  -0.12100819  0.31525288  1.62489078\n",
      "  -1.22292443  0.89356238 -0.80151541  0.5129935   0.06130271 -0.65504254\n",
      "  -0.30394142  0.79215113  0.67426606 -1.06179596 -2.26407744  1.23529768\n",
      "  -0.6585724   0.83397032  0.21349294  0.524717   -0.51216488  0.86855412\n",
      "  -0.54228635 -1.24613728  1.37262426 -0.50900678  1.59100346  0.34245972\n",
      "   0.06387634  2.58445789 -0.66856955 -0.69346368 -0.51898359  0.34464709\n",
      "   0.39595767 -0.64580794 -0.00493841  0.99402871 -0.52160511 -1.15905008\n",
      "  -0.71718411  0.2209618  -1.18921342 -0.23510134 -0.9971751   1.26220595\n",
      "  -0.11366405  0.16017265  0.30385583 -0.44259823 -0.05842949  0.8050542\n",
      "  -0.77824422  0.31283441  0.59162982 -0.28053826 -0.52078475 -0.33064551\n",
      "   0.07099745 -0.90215203  1.47518768 -1.90753558 -0.27915297 -0.12814715\n",
      "   0.71442544 -0.89857543 -1.60921214  0.1169772  -1.06899994 -0.25020754\n",
      "   0.29303915  1.64832365 -0.6992437   1.1621044  -0.56879751  0.70689125\n",
      "   1.3414717  -0.75527191  0.62223779 -0.95338771 -0.05442252  0.3674775\n",
      "   1.18581117  0.89398905 -0.73882613 -1.61252424 -0.86964837 -0.66741755\n",
      "   0.13335751  0.51072039 -0.565402   -0.58035389 -1.24430422 -1.27611511\n",
      "  -1.00038795 -0.99861256 -0.15747921  0.07668175 -0.74195298 -0.01648776\n",
      "   0.26657799  1.22529123  1.38891815 -0.24885467 -1.04726884 -2.12565549\n",
      "   0.48682529 -0.71973387 -0.67908044 -1.48171866  0.22596959 -0.63239075\n",
      "  -0.02976832  1.02604331  0.40115068 -0.06025188  0.63452698 -0.37077074\n",
      "   1.23344844 -0.09768169  1.09821517  0.70398317 -0.25663127 -1.44237336\n",
      "  -0.8293699  -0.38878066  1.16122439  0.44785362 -1.70403305 -1.79786289\n",
      "   0.20189427 -1.90613489  0.93173039  1.33491594  0.99447855  0.04208871\n",
      "   0.85826873  0.98658661 -0.30632972  0.48129291  0.31441649  0.99676154\n",
      "   0.87741407 -0.07767395  1.77958973 -0.52787413  0.27645587  0.54208652\n",
      "   0.70952645  0.63679497  1.42859748  0.69513769 -1.36651229  1.50037133\n",
      "   1.31112686 -0.51404357 -1.18508246  1.88793577  0.51184975 -0.61950847\n",
      "  -0.02774216 -0.68381531 -0.28085401  0.12404568  0.51473615  0.17297501\n",
      "  -0.72569321  0.62181776  0.24030532  2.69122568 -0.1796638   0.68656089\n",
      "  -2.20514342  1.19507102  2.08894328  0.07758078  0.29742174  0.42558686\n",
      "   1.76366085  0.00497409 -1.42417314 -0.20769575 -0.01276536 -1.02142763\n",
      "   1.05191288 -0.45317333  0.59138336 -0.70625996  1.49984983 -0.71127105\n",
      "  -0.11866463 -0.97161669  0.15988359 -1.02179847 -0.34150435 -0.40486587\n",
      "   0.7170378   0.10866537 -0.78890334  1.030343   -1.09493978 -0.84269086\n",
      "   1.38885132  1.41950318  0.96628067 -0.18223374 -1.10777316  0.53604422\n",
      "  -1.96689284  0.790246   -1.38409331  0.28383409 -0.59237161  1.67261185\n",
      "  -0.24368075  0.84622609  0.86309404  1.21643717  0.85425905  0.14554938\n",
      "  -1.35718235 -1.15889371  0.23532923  1.56487309  2.00678568  0.97784841\n",
      "  -0.12211306  1.45428319  1.22065882  0.35723815 -1.26558488 -0.77090646\n",
      "  -0.38325458  0.15581677 -2.48953502  0.78519597  0.75067121  0.43101208\n",
      "  -0.08293852  0.16154499 -0.00833688  0.20724332  0.50368383  1.20482398\n",
      "   0.68509854  1.6859978  -0.37007023  0.32026398  0.24880707  0.04333353\n",
      "  -0.98124853 -1.37715807  0.04190503  0.6772124  -1.7132971  -1.50835967\n",
      "   0.14528999 -0.38489421  0.18110776  0.22367482  0.8786928   0.5491372\n",
      "  -0.90529796 -0.53696561 -0.08070138 -1.89392047 -0.44113337 -0.24763264\n",
      "  -2.99645862  1.22966493 -0.2907812  -0.51165861 -1.59076091 -1.16396031\n",
      "   0.43641117 -1.82822533  0.09949658 -0.47631684 -0.71015457 -0.34082714\n",
      "   0.30576652  0.08022256 -1.02737743  0.38126913 -1.02412534  1.25285483\n",
      "   0.71971167 -1.6887396  -0.99282664 -0.57785129  1.4382096  -0.29599786\n",
      "  -1.50479324 -0.19686317  0.05131284  0.8306683  -0.75958348 -0.66177956\n",
      "   0.82946358  0.16060589 -0.2942444   1.43517712  1.40200005  0.56866764\n",
      "  -1.49454398 -1.3327826  -1.40092766  0.1137429  -0.45633899 -2.24725423\n",
      "   1.00433498  0.99158646 -1.95607191  0.88855049 -0.45744344 -1.03255871\n",
      "  -1.48933673 -1.48151946 -0.47851615 -1.11719455  0.58194573 -0.52724203\n",
      "   0.08120948  1.20888745  1.51767079]\n",
      " [-0.66471679 -0.37766258 -0.83821148 -0.87257037 -1.47342367  1.38154312\n",
      "  -0.16062141  0.49296246  0.95324149 -0.74745853 -0.31739128 -0.51973928\n",
      "  -0.9952713  -1.07430168 -0.50991719 -0.84535065  0.32452354 -1.15295778\n",
      "  -0.51753381 -0.34796406 -0.38065464  0.02897422  1.61424551  2.25456605\n",
      "   0.23481504 -0.81736177  0.83660918 -0.1100067  -0.05313853  0.79329574\n",
      "   0.06366011 -0.37706357 -0.02127058 -3.1021892  -1.17508918  0.80700523\n",
      "   0.1248405   0.61132706  0.17289145 -0.9770216   1.50638593 -0.86543363\n",
      "  -0.07205785  1.58092372 -1.14675396  0.44360435 -0.54157814  0.11171799\n",
      "   0.3179824  -0.26565779  1.96591407 -1.54397067  0.76528213  0.37610943\n",
      "  -0.76534545  0.29600664  1.82333552 -0.20648654  0.02153793  0.32263097\n",
      "   0.54876649 -0.16304115 -0.5949876  -0.10243587  0.56691168 -0.08593904\n",
      "   0.87569325  1.13394233  1.14312553  1.74218025  2.02390208  0.55046436\n",
      "  -1.38813005  0.08422837  1.3683957  -0.89201502  0.88671838 -0.06378534\n",
      "  -1.93662062 -1.20633518 -0.84870231  1.0229843  -1.22709447 -0.19344788\n",
      "   0.30260864 -0.58766306  0.0259212   0.08451611 -0.19986311 -0.26643365\n",
      "   1.58591271 -0.03537447  0.20122368  0.4839675  -0.30071042 -0.35951273\n",
      "   1.18231932 -1.80743801 -0.30445586 -0.17263779 -0.97660856  0.62759202\n",
      "  -0.86836061  0.75138195  0.60163712 -0.19325163 -0.27114593  1.29365769\n",
      "   0.55260223 -0.31247013  0.04413929  0.82451543 -0.63510791 -0.89810817\n",
      "   0.41118833 -0.66201506 -0.27412783 -1.37512141  0.45413888 -0.97629755\n",
      "   1.8652554  -0.51120636  0.503327    0.56794014  0.12872707 -0.12802045\n",
      "  -0.97251814  0.25374851  0.74701207 -0.17026265 -1.23934928  0.14608519\n",
      "  -0.44090933  2.67518011  0.23342555 -1.37875662  0.20825656 -0.48188435\n",
      "   0.43996738  0.33059829  0.63716643  0.73990596  0.5845416  -0.10582068\n",
      "  -0.58340606 -0.27544308  2.4326085  -1.71733287 -0.28169268  0.96822764\n",
      "   0.08171363 -0.73430883 -0.85979513  1.35550339 -0.07769886 -1.51200806\n",
      "  -0.70830362 -1.64253009  0.5685148  -0.51839362 -0.45359827 -0.10130949\n",
      "   1.02730393 -0.7867631  -0.72848856 -0.53606131 -0.37432421  0.53279257\n",
      "   0.90435233 -0.24298286 -1.26071502 -0.23328665 -0.17252338  0.37860612\n",
      "   0.599606    0.85250155 -0.0142285  -1.07949104 -0.58536576  1.07498252\n",
      "   0.2758016  -0.69934618  0.31068724  0.39308323 -0.51054876 -0.14830347\n",
      "  -0.38400974  1.49121573 -0.77999075 -0.37930229 -0.15869375 -0.86406483\n",
      "   0.1547374   0.56597082 -0.30556563  0.53658025 -0.94735226 -0.0880575\n",
      "  -0.9963793  -1.34907956  0.98417977 -1.00278141  1.77812487  1.37279895\n",
      "  -1.41225166 -0.22387826  1.10127457  1.57041256 -0.02973435  0.91146542\n",
      "   1.65053451 -0.10145611 -0.29061908 -1.5790469  -0.74640095 -2.05593056\n",
      "  -0.52590657 -0.81063331 -0.16206445 -0.08838056 -0.62822557  0.20095326\n",
      "  -0.22371502  0.30874512  2.15992021  0.8235799  -0.81243078 -0.61382492\n",
      "  -1.6446079  -1.10484034 -0.30534317 -0.81651889  0.36025586 -0.16948325\n",
      "  -0.45690943  1.32928382  0.46013184 -0.38691159  0.48672121  0.05417547\n",
      "   0.65727741  1.4223475   0.65349249 -0.29291094 -2.26184708  0.1363457\n",
      "   0.76948262  0.39279883  1.44469007  0.36051896  0.27113278  0.67627262\n",
      "  -1.16198487 -0.55583391  0.88602913  1.06045168  1.85639693  1.21184148\n",
      "  -1.27567373  0.75265443  0.63210044  0.10232914  0.00489269  1.14734338\n",
      "  -1.41637854 -0.63561917 -0.90244463  1.41543381  1.64561418  0.34706815\n",
      "  -0.79098241  1.6447564   0.98319767  0.80538894 -1.76811474 -0.11871962\n",
      "  -0.14059511  0.38067323 -1.01302172 -1.01849338  0.76005663 -1.43949339\n",
      "  -0.93099842 -0.17505307  0.2152765   0.45941958  0.8726264   1.1189612\n",
      "   1.89711265 -0.17075723 -0.71135529  0.88823295 -0.09141556  1.27104518\n",
      "   0.82090965  1.94009544  0.6251212  -1.0138732  -0.05886067  0.6812385\n",
      "   0.34061291  0.1126515  -0.01636029  0.24076367  1.90397299  0.12175927\n",
      "  -0.65644504 -0.97290515  0.28051071  0.26272003  0.81280173 -0.68438888\n",
      "  -1.35963858 -0.1527919   0.61698424 -0.74422769 -0.24319093 -0.40990637\n",
      "   1.37889523 -0.57123376  0.96575349 -0.01960688 -2.4231382  -0.77619681\n",
      "  -1.14464164  0.8303658   1.34297173  0.66361682 -1.07365716  0.61055067\n",
      "  -0.43395674  0.66402997 -0.95787512 -0.49780978 -0.650235    1.41421705\n",
      "  -0.42664173 -1.25720299 -1.17216234  1.67939936  1.33854195  1.09359148\n",
      "  -0.09218918  0.12455401  0.21362138 -0.26514622 -0.85288212  0.96452643\n",
      "   0.16413825 -0.2702373  -0.88583681  0.16381899 -0.53340371  2.22610228\n",
      "  -0.36212411 -0.20832788 -0.98428652  0.50693492  0.43776503 -1.08337802\n",
      "  -0.93492253  0.19739838 -0.26789575 -0.8641379  -0.60952598  0.21269733\n",
      "   0.24242918  1.05229108  0.90572377 -0.89033164 -0.29739033 -1.15713849\n",
      "   0.47745308 -1.63240834  1.20886806  0.83899171  0.26268603  0.66410455\n",
      "  -1.05505252 -0.09878578  1.20920374  0.41132116  0.66419838 -0.28497946\n",
      "   0.14469519  0.21205368 -0.27554652 -0.96302764 -1.4311071   0.05944542\n",
      "   0.29197147 -0.72206575 -0.02047667  0.55799084 -0.93916156  0.67666423\n",
      "   1.89053508 -0.10312811 -0.65318093]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Apply Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Sanity check\n",
    "print(\"X_scaled shape:\", X_scaled.shape)\n",
    "print(\"Sample scaled values:\\n\", X_scaled[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83161ebb",
   "metadata": {},
   "source": [
    "MODELS PLANNING TO USE:\n",
    "\n",
    "| Model                                        | Why We're Using It                        | Strengths                                             |\n",
    "| -------------------------------------------- | ----------------------------------------- | ----------------------------------------------------- |\n",
    "| 🔸 **SVM (Support Vector Machine)**          | Handles high-dimensional data well        | Good with small datasets, finds optimal boundary      |\n",
    "| 🔸 **LightGBM**                              | Fast, handles noisy high-dimensional data | Great with many features, built-in regularization     |\n",
    "| 🔸 **Logistic Regression (L2)**              | Simple, interpretable baseline            | Can work well with proper scaling, avoids overfitting |\n",
    "| 🔸 **Voting Ensemble (SVM + LGBM + LogReg)** | Combines multiple models for robustness   | Reduces bias/variance, improves generalization        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "520a0f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 5-Fold Cross-Validation Results\n",
      "\n",
      "📌 SVM (Linear)\n",
      "   ✅ Mean Accuracy: 0.5358\n",
      "   🎯 Mean F1 Score: 0.5627\n",
      "--------------------------------------------------\n",
      "📌 Logistic (L2)\n",
      "   ✅ Mean Accuracy: 0.5233\n",
      "   🎯 Mean F1 Score: 0.5544\n",
      "--------------------------------------------------\n",
      "📌 Voting Ensemble\n",
      "   ✅ Mean Accuracy: 0.5233\n",
      "   🎯 Mean F1 Score: 0.5544\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# # STEP 1: Load and preprocess\n",
    "# df = pd.read_csv(\"EDA/features.csv\")\n",
    "# X = df.drop(columns=['participant_id', 'phq8_score', 'phq8_binary'])\n",
    "# y = df['phq8_binary']\n",
    "\n",
    "# # STEP 2: Feature Scaling\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# STEP 3: Define Models\n",
    "models = {\n",
    "    \"SVM (Linear)\": SVC(kernel='linear', probability=True, random_state=42),\n",
    "    # \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "    \"Logistic (L2)\": LogisticRegression(penalty='l2', max_iter=1000, random_state=42),\n",
    "}\n",
    "\n",
    "# STEP 4: Voting Ensemble\n",
    "voting = VotingClassifier(\n",
    "    estimators=[('svm', models[\"SVM (Linear)\"]),\n",
    "                # ('lgbm', models[\"LightGBM\"]),\n",
    "                ('logreg', models[\"Logistic (L2)\"])],\n",
    "    voting='soft'\n",
    ")\n",
    "models[\"Voting Ensemble\"] = voting\n",
    "\n",
    "# STEP 5: Evaluate Each Model\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"🔍 5-Fold Cross-Validation Results\\n\")\n",
    "for name, model in models.items():\n",
    "    f1_scores = cross_val_score(model, X_scaled, y, cv=skf, scoring='f1')\n",
    "    acc_scores = cross_val_score(model, X_scaled, y, cv=skf, scoring='accuracy')\n",
    "    \n",
    "    print(f\"📌 {name}\")\n",
    "    print(f\"   ✅ Mean Accuracy: {acc_scores.mean():.4f}\")\n",
    "    print(f\"   🎯 Mean F1 Score: {f1_scores.mean():.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acaa67a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
