{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25a812e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (119, 402)\n",
      "Missing values in features: 0\n",
      "Missing values in target: 0\n",
      "Class distribution:\n",
      " phq8_binary\n",
      "0    60\n",
      "1    59\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"../EDA/final_features_with_labels.csv\")\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "\n",
    "# Drop 'phq8_score' (we're doing classification now)\n",
    "df = df.drop(columns=['phq8_score'])\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['participant_id', 'phq8_binary'])\n",
    "y = df['phq8_binary']\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in features:\", X.isnull().sum().sum())\n",
    "print(\"Missing values in target:\", y.isnull().sum())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875983ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_scaled shape: (119, 399)\n",
      "Sample scaled values:\n",
      " [[-1.35986083 -0.38167097 -0.40013599 -0.5827175   0.063736   -0.88409772\n",
      "   1.2964311  -0.01696282  1.24046929 -0.41603474 -0.33552881  1.00452126\n",
      "   0.31881237 -0.0313718  -0.46768604  1.5524155   1.72558708 -0.28717188\n",
      "  -0.6625099   0.77091904  0.7383851  -0.09354983 -0.39120243 -0.09114678\n",
      "   1.2023181   0.07143761  0.93260601 -0.38835408 -0.26145164 -1.16169782\n",
      "  -0.39784516 -0.33646232 -0.76457215  0.19078856 -1.03879824  0.59659978\n",
      "  -1.49363314 -1.05493209 -0.23458989  0.98028671 -0.27862815 -0.12242382\n",
      "  -0.23855562  0.78797272  0.59639936  1.84056788  1.07102955 -1.02806865\n",
      "   1.48614194  0.35643309 -0.0773993  -0.73394069 -0.59250361  2.95817174\n",
      "  -0.01523424  2.52450991 -0.7473162  -1.14729798  0.20179246  0.49868479\n",
      "  -1.199556    2.41656493  0.18483749  1.38407909 -1.25554288  1.19220995\n",
      "   0.00616795 -0.32395166 -1.54880091 -0.0634082   0.4600402  -0.03223983\n",
      "  -0.38509671  0.60837899  0.29771948 -0.09536796  0.44160766  1.62677806\n",
      "  -1.2520411   0.90250921 -0.77456843  0.49750123 -0.09437108 -0.61959585\n",
      "  -0.35204546  0.82567155  0.58447522 -1.07594242 -2.33228739  1.25662514\n",
      "  -0.71693002  0.90590823  0.23606776  0.63696254 -0.4412761   0.88002439\n",
      "  -0.49772741 -1.25382461  1.31350157 -0.5159221   1.70257299  0.40479533\n",
      "   0.14317716  2.78965311 -0.56255246 -0.64162671 -0.61009044  0.43805688\n",
      "   0.42352749 -0.70413566  0.06929748  0.85119722 -0.59643274 -1.24699692\n",
      "  -0.74007849  0.20175781 -1.24700516 -0.24647285 -1.00532109  1.44642285\n",
      "   0.00641194  0.19067097  0.12718109 -0.56923281 -0.1406614   0.70518618\n",
      "  -0.85638631  0.35327964  0.56508791 -0.34389399 -0.53625436 -0.3394116\n",
      "   0.05035234 -0.8769419   1.3923509  -1.92989645 -0.28422597 -0.0738116\n",
      "   0.93088801 -0.82130265 -1.482425   -0.03412195 -0.86934662 -0.30254194\n",
      "   0.1963212   1.30549227 -0.69430631  1.19818495 -0.57099623  0.80819233\n",
      "   1.39640445 -0.62568457  0.50390649 -1.05997722 -0.12157428  0.4416062\n",
      "   1.10173628  0.83142392 -0.71907182 -1.5171635  -0.90940654 -0.73551482\n",
      "   0.19719241  0.54807954 -0.52404578 -0.56122881 -1.32475356 -1.32914899\n",
      "  -1.08959419 -1.03472761 -0.2282913   0.04637019 -0.6666991  -0.06785311\n",
      "   0.24947363  1.19276503  1.49725952 -0.16350437 -1.09619844 -2.07681667\n",
      "   0.67412318 -0.8418745  -0.81655317 -1.62190774  0.26289614 -0.58036437\n",
      "   0.08874959  1.12838413  0.38455376 -0.18446692  0.53048193 -0.46567377\n",
      "   1.04443913 -0.0777928   1.23465727  0.85891352 -0.23841377 -1.44337528\n",
      "  -0.77729448 -0.34005691  1.24621365  0.42296601 -1.66409884 -1.99085314\n",
      "   0.21081996 -1.97545334  0.92407537  1.44800783  0.88962391 -0.02018369\n",
      "   0.95871906  0.99858248 -0.38165502  0.52901464  0.35067026  1.10316947\n",
      "   0.87390771 -0.08675504  1.95257072 -0.54785809  0.2717743   0.39133494\n",
      "   0.64519445  0.77238071  1.48023366  0.714036   -1.44392847  1.61347473\n",
      "   1.23431444 -0.62210024 -1.27361997  1.90617278  0.55500913 -0.66213772\n",
      "   0.04330932 -0.58747018 -0.16165564  0.16581353  0.3578388   0.09101712\n",
      "  -0.60721648  0.52021215  0.11801137  2.58386524 -0.16878183  0.6687572\n",
      "  -2.22901879  1.23345227  1.9828106   0.09813747  0.3492179   0.34973264\n",
      "   1.69099478  0.10820529 -1.54792781 -0.3376104  -0.08654702 -1.01569385\n",
      "   0.96384167 -0.49660761  0.66170315 -0.80960971  1.5101081  -0.61050436\n",
      "  -0.19032652 -0.69374982  0.2054779  -1.08584999 -0.34707719 -0.46127111\n",
      "   0.61751978  0.19711591 -0.75505032  1.15194082 -1.15190945 -0.92435109\n",
      "   1.43618531  1.56324562  0.88789937 -0.09002287 -1.20109724  0.50372927\n",
      "  -2.22460199  0.90067685 -1.44581058  0.38696074 -0.70984311  1.76594014\n",
      "  -0.05073211  0.88845082  0.80283019  1.30365191  0.94341192  0.32025444\n",
      "  -1.39722005 -1.23230258  0.23760677  1.56395663  1.99024806  1.00588615\n",
      "  -0.04814785  1.59547734  1.30950876  0.43912874 -1.41839324 -0.87492353\n",
      "  -0.43411974  0.29296052 -2.54729127  0.68135147  0.78333851  0.55388673\n",
      "  -0.0736321   0.26358837  0.04876072  0.2372938   0.52100358  1.25613987\n",
      "   0.67929506  1.84855366 -0.38812516  0.47575008  0.20282175 -0.06490344\n",
      "  -1.14191738 -1.3025324   0.09321506  0.58517271 -1.59870209 -1.60114745\n",
      "   0.20264093 -0.1823738   0.13301615  0.19428559  0.75935269  0.62898027\n",
      "  -0.97873544 -0.55606855  0.02654451 -1.85617021 -0.5427905  -0.23699126\n",
      "  -2.90915866  1.08643606 -0.25198739 -0.48381879 -1.4131853  -1.21746791\n",
      "   0.31168241 -1.91424941  0.15277819 -0.46867409 -0.7847679  -0.37062422\n",
      "   0.20562215  0.01179365 -0.98965389  0.35675718 -0.89870993  1.10052195\n",
      "   0.7425975  -1.93184121 -1.08277428 -0.61733695  1.40136766 -0.27319701\n",
      "  -1.50130436 -0.17380994  0.04338786  0.80416578 -0.76947632 -0.60616866\n",
      "   0.88683608  0.22872652 -0.2799707   1.51025152  1.41876114  0.56387344\n",
      "  -1.70357251 -1.23285631 -1.37538767  0.10138578 -0.49452407 -2.23843179\n",
      "   1.04558765  1.11531968 -1.96176692  0.75585122 -0.45335692 -1.09648377\n",
      "  -1.49470723 -1.54103597 -0.56954842 -1.23001918  0.39877039 -0.55276719\n",
      "   0.03991076  1.17862369  1.55305691]\n",
      " [-0.65416607 -0.38167097 -0.91137273 -0.98626477 -1.50575651  1.51802181\n",
      "  -0.21704336  0.43736843  1.1573883  -0.73994259 -0.33552881 -0.47510164\n",
      "  -1.09638876 -1.10575582 -0.46768604 -0.77574339  0.32076019 -1.18466766\n",
      "  -0.49572476 -0.41971437 -0.38552984  0.05417354  1.73723053  2.37739179\n",
      "   0.25780818 -0.90546458  0.83745036 -0.15702733 -0.07974041  0.65384026\n",
      "   0.09617299 -0.40432753 -0.12151223 -3.13504561 -1.21146491  0.79967177\n",
      "   0.22374669  0.66188283  0.11370839 -1.03073639  1.59685646 -0.79295566\n",
      "  -0.06215883  1.60793897 -1.08077969  0.48454494 -0.61963579  0.15968861\n",
      "   0.26832782 -0.23529568  1.64852396 -1.46152717  0.66628631  0.41734638\n",
      "  -0.78485175  0.39309478  1.95813532 -0.25384208  0.07231798  0.37785535\n",
      "   0.49206834 -0.22401783 -0.72784768 -0.07322262  0.53635061 -0.03174128\n",
      "   0.85251572  1.25438445  1.12696034  1.85864918  2.06942348  0.55513615\n",
      "  -1.38799789  0.13116589  1.22522578 -0.89438147  1.00613051 -0.07082961\n",
      "  -1.93862363 -1.26316341 -0.82334161  1.01322444 -1.4168006  -0.15954169\n",
      "   0.24821192 -0.48864459 -0.03209293  0.10421639 -0.24283359 -0.31297454\n",
      "   1.56437392 -0.01068512  0.2228091   0.60089502 -0.22618241 -0.4237211\n",
      "   1.18510286 -1.8087339  -0.35825013 -0.15302825 -1.02749391  0.69369703\n",
      "  -0.82093115  0.85113128  0.79986305 -0.14794226 -0.37035671  1.41116699\n",
      "   0.57316381 -0.37527474  0.11917609  0.68788722 -0.70138511 -0.97662731\n",
      "   0.37707114 -0.67240962 -0.32180197 -1.34108791  0.42239305 -0.98602819\n",
      "   1.9944409  -0.53721714  0.31106058  0.46568908  0.05548622 -0.2640046\n",
      "  -1.0491426   0.29167897  0.72045144 -0.23586958 -1.26512737  0.1176164\n",
      "  -0.46193218  2.42605032  0.18345847 -1.41006708  0.21669662 -0.43333762\n",
      "   0.65275497  0.46856498  0.64939431  0.58780575  0.6277187  -0.16034129\n",
      "  -0.65534828 -0.3147833   2.31561777 -1.82450527 -0.26331648  1.05997233\n",
      "   0.14616092 -0.60376103 -1.00113488  1.12079791 -0.14474286 -1.48505292\n",
      "  -0.82701635 -1.79820651  0.5744818  -0.49956988 -0.48040855 -0.16200492\n",
      "   1.14607015 -0.78578242 -0.67374986 -0.5168992  -0.38850032  0.60148332\n",
      "   0.95771002 -0.28903503 -1.37698168 -0.26205746 -0.11808986  0.33267974\n",
      "   0.5819882   0.82783472 -0.0287615  -0.98772999 -0.61536275  1.20977475\n",
      "   0.47175993 -0.8231682   0.20315473  0.26498627 -0.52271406 -0.1260088\n",
      "  -0.26993399  1.6035119  -0.88180044 -0.49652898 -0.26292175 -0.97989241\n",
      "   0.06178786  0.54592587 -0.19423813  0.67656279 -0.94554893 -0.12248749\n",
      "  -0.94010877 -1.29281912  1.06560017 -0.97025382  1.91070776  1.52920647\n",
      "  -1.48066384 -0.28303914  1.10472481  1.69491904 -0.13554768  0.82770498\n",
      "   1.71513121 -0.1248819  -0.36524561 -1.52214551 -0.70768554 -1.72893005\n",
      "  -0.55460215 -0.84393847 -0.14179791 -0.12136966 -0.69388894  0.07097768\n",
      "  -0.33211543  0.45256923  2.22296266  0.84126588 -0.85563237 -0.65977\n",
      "  -1.80078902 -1.26004652 -0.32186307 -0.84474477  0.40628736 -0.21404384\n",
      "  -0.3707653   1.27250704  0.58423248 -0.37933946  0.33183619 -0.02385478\n",
      "   0.70303235  1.3639282   0.54488103 -0.37380535 -2.1392137   0.09724634\n",
      "   0.61954571  0.47630837  1.37113423  0.37085519  0.32352211  0.59027584\n",
      "  -1.22578395 -0.4180345   0.71263327  0.90005342  1.82121204  1.25381141\n",
      "  -1.32452006  0.71019091  0.7038221   0.00401372 -0.09291951  1.32729496\n",
      "  -1.55349572 -0.41521605 -0.81356888  1.48214402  1.62957429  0.27264932\n",
      "  -0.73056609  1.74425303  1.06353974  0.92319738 -1.78786903 -0.2031781\n",
      "  -0.127959    0.47619951 -1.04968251 -0.94369515  0.78638492 -1.5070662\n",
      "  -1.08294009 -0.08862148  0.28629479  0.55861128  0.74943478  1.22254967\n",
      "   1.91516786 -0.18653909 -0.81397323  0.95449173  0.04561514  1.51360401\n",
      "   0.71611008  1.93638535  0.63047492 -1.06102124 -0.04420235  0.70823068\n",
      "   0.42020887  0.21307484  0.06119472  0.32401629  1.80622675  0.00796037\n",
      "  -0.69535347 -0.80673251  0.27770841  0.21361015  0.8468972  -0.47854948\n",
      "  -1.36554934 -0.0253906   0.72480418 -0.72317647 -0.2543451  -0.36562232\n",
      "   1.36503299 -0.50331038  0.92332386  0.13056249 -2.4842818  -0.84430941\n",
      "  -1.30266263  0.96224796  1.34176994  0.57265376 -0.98081084  0.71504238\n",
      "  -0.39572185  0.72506848 -0.97643799 -0.55800529 -0.59153571  1.56473667\n",
      "  -0.50648867 -1.28856207 -1.06397654  1.70125826  1.31121489  1.13368682\n",
      "  -0.11032521 -0.01736432  0.23866128 -0.22445017 -0.76885782  0.93453417\n",
      "   0.04015001 -0.36743761 -0.85166782  0.18027278 -0.61608381  2.09586643\n",
      "  -0.44130262 -0.27445111 -0.94364147  0.48630852  0.45765002 -1.11406481\n",
      "  -0.92702589  0.08651261 -0.32292547 -0.89660674 -0.34159881  0.22894586\n",
      "   0.31599556  1.05426563  0.86658602 -0.87676178 -0.30911553 -1.09935677\n",
      "   0.52493534 -1.50657986  1.266134    0.89444793  0.33354913  0.66286915\n",
      "  -1.22708732 -0.01750093  1.23064031  0.40631611  0.60274132 -0.19276127\n",
      "   0.17104988  0.29992    -0.30922786 -0.97932427 -1.42814298 -0.0314449\n",
      "   0.36409286 -0.79982016 -0.12132615  0.46707662 -0.99514039  0.60780135\n",
      "   1.80643191 -0.10270476 -0.52142328]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Apply Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Sanity check\n",
    "print(\"X_scaled shape:\", X_scaled.shape)\n",
    "print(\"Sample scaled values:\\n\", X_scaled[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83161ebb",
   "metadata": {},
   "source": [
    "MODELS PLANNING TO USE:\n",
    "\n",
    "| Model                                        | Why We're Using It                        | Strengths                                             |\n",
    "| -------------------------------------------- | ----------------------------------------- | ----------------------------------------------------- |\n",
    "| 🔸 **SVM (Support Vector Machine)**          | Handles high-dimensional data well        | Good with small datasets, finds optimal boundary      |\n",
    "| 🔸 **LightGBM**                              | Fast, handles noisy high-dimensional data | Great with many features, built-in regularization     |\n",
    "| 🔸 **Logistic Regression (L2)**              | Simple, interpretable baseline            | Can work well with proper scaling, avoids overfitting |\n",
    "| 🔸 **Voting Ensemble (SVM + LGBM + LogReg)** | Combines multiple models for robustness   | Reduces bias/variance, improves generalization        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "520a0f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 5-Fold Cross-Validation Results\n",
      "\n",
      "📌 SVM (Linear)\n",
      "   ✅ Mean Accuracy: 0.5116\n",
      "   🎯 Mean F1 Score: 0.4457\n",
      "--------------------------------------------------\n",
      "📌 Logistic (L2)\n",
      "   ✅ Mean Accuracy: 0.5116\n",
      "   🎯 Mean F1 Score: 0.4498\n",
      "--------------------------------------------------\n",
      "📌 Voting Ensemble\n",
      "   ✅ Mean Accuracy: 0.5116\n",
      "   🎯 Mean F1 Score: 0.4498\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# STEP 3: Define Models\n",
    "models = {\n",
    "    \"SVM (Linear)\": SVC(kernel='linear', probability=True, random_state=42),\n",
    "    # \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "    \"Logistic (L2)\": LogisticRegression(penalty='l2', max_iter=1000, random_state=42),\n",
    "}\n",
    "\n",
    "# STEP 4: Voting Ensemble\n",
    "voting = VotingClassifier(\n",
    "    estimators=[('svm', models[\"SVM (Linear)\"]),\n",
    "                # ('lgbm', models[\"LightGBM\"]),\n",
    "                ('logreg', models[\"Logistic (L2)\"])],\n",
    "    voting='soft'\n",
    ")\n",
    "models[\"Voting Ensemble\"] = voting\n",
    "\n",
    "# STEP 5: Evaluate Each Model\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"🔍 5-Fold Cross-Validation Results\\n\")\n",
    "for name, model in models.items():\n",
    "    f1_scores = cross_val_score(model, X_scaled, y, cv=skf, scoring='f1')\n",
    "    acc_scores = cross_val_score(model, X_scaled, y, cv=skf, scoring='accuracy')\n",
    "    \n",
    "    print(f\"📌 {name}\")\n",
    "    print(f\"   ✅ Mean Accuracy: {acc_scores.mean():.4f}\")\n",
    "    print(f\"   🎯 Mean F1 Score: {f1_scores.mean():.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca567e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
